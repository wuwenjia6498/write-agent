"""
å·¥ä½œæµå¼•æ“
å®ç°9æ­¥SOPçš„AIé€»è¾‘ï¼Œæ”¯æŒæ•°æ®åº“æŒä¹…åŒ–å’Œå‘é‡æ£€ç´¢
"""

from typing import Dict, Any, Optional, List
import json
from pathlib import Path
from .ai_service import ai_service
from .db_service import db_service

class WorkflowEngine:
    """å·¥ä½œæµæ‰§è¡Œå¼•æ“"""
    
    def __init__(self):
        """åˆå§‹åŒ–å·¥ä½œæµå¼•æ“"""
        self.configs_dir = Path(__file__).parent.parent / "configs"
    
    def load_channel_config(self, channel_id: str) -> Dict[str, Any]:
        """åŠ è½½é¢‘é“é…ç½®"""
        config_file = self.configs_dir / "channels" / f"{channel_id}.json"
        with open(config_file, "r", encoding="utf-8") as f:
            return json.load(f)
    
    def load_blocked_words(self) -> Dict[str, Any]:
        """
        åŠ è½½å±è”½è¯åº“
        æ”¯æŒ Markdown è¡¨æ ¼æ ¼å¼å’Œ JSON æ ¼å¼
        """
        # ä¼˜å…ˆä½¿ç”¨ Markdown æ ¼å¼
        md_file = self.configs_dir / "global" / "blocked_words.md"
        json_file = self.configs_dir / "global" / "blocked_words.json"
        
        if md_file.exists():
            return self._parse_blocked_words_markdown(md_file)
        elif json_file.exists():
            with open(json_file, "r", encoding="utf-8") as f:
                return json.load(f)
        else:
            return {"categories": {}}
    
    def _parse_blocked_words_markdown(self, filepath: Path) -> Dict[str, Any]:
        """
        è§£æ Markdown æ ¼å¼çš„å±è”½è¯åº“
        ä»è¡¨æ ¼ä¸­æå–ï¼šç¦ç”¨çŸ­è¯­ã€åŸå› ã€æ›¿æ¢å»ºè®®
        """
        with open(filepath, "r", encoding="utf-8") as f:
            content = f.read()
        
        result = {
            "blocked_words_config": {
                "version": "2.0",
                "description": "Markdown æ ¼å¼å±è”½è¯åº“",
                "format": "markdown"
            },
            "categories": {}
        }
        
        # æŒ‰äºŒçº§æ ‡é¢˜åˆ†å‰²
        import re
        sections = re.split(r'\n## ', content)
        
        for section in sections[1:]:  # è·³è¿‡ç¬¬ä¸€ä¸ªï¼ˆæ ‡é¢˜å‰çš„å†…å®¹ï¼‰
            lines = section.strip().split('\n')
            if not lines:
                continue
            
            category_name = lines[0].strip()
            
            # è·³è¿‡"å®¡æ ¡æ£€æŸ¥æ¸…å•"ç­‰éè¡¨æ ¼åŒºåŸŸ
            if 'æ£€æŸ¥æ¸…å•' in category_name:
                continue
            
            patterns = []
            in_table = False
            
            for line in lines[1:]:
                line = line.strip()
                
                # è·³è¿‡è¡¨å¤´å’Œåˆ†éš”çº¿
                if line.startswith('| ç¦ç”¨çŸ­è¯­') or line.startswith('|---'):
                    in_table = True
                    continue
                
                # è§£æè¡¨æ ¼è¡Œ
                if in_table and line.startswith('|') and line.endswith('|'):
                    cells = [cell.strip() for cell in line.split('|')[1:-1]]
                    if len(cells) >= 3:
                        patterns.append({
                            "phrase": cells[0],
                            "reason": cells[1],
                            "replacement": cells[2]
                        })
            
            if patterns:
                # ç”Ÿæˆ category key
                category_key = category_name.replace('ï¼ˆ', '_').replace('ï¼‰', '').replace(' ', '_')
                result["categories"][category_key] = {
                    "name": category_name,
                    "patterns": patterns
                }
        
        return result
    
    async def execute_step_1(self, brief: str, channel_id: str) -> Dict[str, Any]:
        """
        Step 1: ç†è§£éœ€æ±‚ & ä¿å­˜Brief
        """
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªéœ€æ±‚åˆ†æä¸“å®¶ã€‚è¯·ä»”ç»†åˆ†æç”¨æˆ·çš„åˆ›ä½œéœ€æ±‚ï¼Œæå–å…³é”®ä¿¡æ¯ã€‚

è¾“å‡ºæ ¼å¼ï¼š
1. ä¸»é¢˜ï¼šxxx
2. ç›®æ ‡è¯»è€…ï¼šxxx
3. æœŸæœ›å­—æ•°ï¼šxxx
4. ç‰¹æ®Šè¦æ±‚ï¼šxxx
5. å…³é”®è¯ï¼šxxx
"""
        
        think_aloud = f"ğŸ“‹ æ­£åœ¨åˆ†æéœ€æ±‚...\nç”¨æˆ·è¾“å…¥ï¼š{brief[:100]}..."
        
        result = await ai_service.generate_content(
            system_prompt=system_prompt,
            user_message=f"è¯·åˆ†æä»¥ä¸‹åˆ›ä½œéœ€æ±‚ï¼š\n\n{brief}",
            temperature=0.3
        )
        
        return {
            "output": result,
            "think_aloud": think_aloud
        }
    
    async def execute_step_2(self, brief_analysis: str, channel_id: str) -> Dict[str, Any]:
        """
        Step 2: ä¿¡æ¯æœç´¢ä¸çŸ¥è¯†ç®¡ç†
        """
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¿¡æ¯è°ƒç ”ä¸“å®¶ã€‚æ ¹æ®åˆ›ä½œéœ€æ±‚ï¼Œåˆ—å‡ºéœ€è¦è°ƒç ”çš„ä¿¡æ¯ç‚¹ã€‚

æ³¨æ„ï¼š
- åªåˆ—å‡ºç¡®å®éœ€è¦è°ƒç ”çš„å†…å®¹
- ä¸ç¼–é€ ä¿¡æ¯
- æ ‡æ³¨ä¿¡æ¯æ¥æºçš„é‡è¦æ€§

è¾“å‡ºæ ¼å¼ï¼š
éœ€è¦è°ƒç ”çš„ä¿¡æ¯ï¼š
1. xxxï¼ˆæ¥æºï¼šå®˜æ–¹æ–‡æ¡£/å­¦æœ¯è®ºæ–‡/æƒå¨åª’ä½“ï¼‰
2. xxx
...

å¦‚æœä¸éœ€è¦é¢å¤–è°ƒç ”ï¼Œè¯´æ˜åŸå› ã€‚
"""
        
        think_aloud = "ğŸ” æ­£åœ¨åˆ†æéœ€è¦è°ƒç ”çš„ä¿¡æ¯ç‚¹..."
        
        result = await ai_service.generate_content(
            system_prompt=system_prompt,
            user_message=f"æ ¹æ®ä»¥ä¸‹éœ€æ±‚åˆ†æï¼Œåˆ—å‡ºéœ€è¦è°ƒç ”çš„ä¿¡æ¯ï¼š\n\n{brief_analysis}",
            temperature=0.3
        )
        
        return {
            "output": result,
            "think_aloud": think_aloud
        }
    
    async def execute_step_3(self, brief_analysis: str, channel_id: str) -> Dict[str, Any]:
        """
        Step 3: é€‰é¢˜è®¨è®ºï¼ˆå¿…åšå¡ç‚¹ï¼‰
        """
        channel_config = self.load_channel_config(channel_id)
        
        system_prompt = f"""{channel_config['system_prompt']['role']}

è¯·æ ¹æ®ç”¨æˆ·éœ€æ±‚æä¾›3-4ä¸ªé€‰é¢˜æ–¹å‘ã€‚

æ¯ä¸ªé€‰é¢˜åŒ…å«ï¼š
1. æ ‡é¢˜ï¼ˆå¸å¼•äººä½†ä¸æ ‡é¢˜å…šï¼‰
2. æ ¸å¿ƒè§‚ç‚¹
3. å¤§çº²ï¼ˆ3-5ä¸ªè¦ç‚¹ï¼‰
4. é¢„ä¼°å·¥ä½œé‡ï¼ˆå­—æ•°ã€æ‰€éœ€ç´ æï¼‰
5. ä¼˜åŠ£åˆ†æ

å†™ä½œé£æ ¼è¦æ±‚ï¼š
{chr(10).join(['- ' + style for style in channel_config['system_prompt']['writing_style']])}
"""
        
        think_aloud = f"ğŸ’¡ æ­£åœ¨ä¸º'{channel_config['channel_name']}'é¢‘é“ç”Ÿæˆé€‰é¢˜æ–¹æ¡ˆ...\n\næ€è€ƒé‡ç‚¹ï¼š\n- ç¬¦åˆé¢‘é“è°ƒæ€§\n- é¿å…ç©ºæ´å¥—è¯\n- æœ‰ç‹¬ç‰¹è§†è§’"
        
        result = await ai_service.generate_content(
            system_prompt=system_prompt,
            user_message=f"åŸºäºä»¥ä¸‹éœ€æ±‚åˆ†æï¼Œæä¾›3-4ä¸ªé€‰é¢˜æ–¹å‘ï¼š\n\n{brief_analysis}",
            temperature=0.8,
            max_tokens=6000
        )
        
        return {
            "output": result,
            "think_aloud": think_aloud,
            "is_checkpoint": True  # å¡ç‚¹ï¼Œéœ€è¦ç”¨æˆ·ç¡®è®¤
        }
    
    async def execute_step_4(self, selected_topic: str) -> Dict[str, Any]:
        """
        Step 4: åˆ›å»ºåä½œæ–‡æ¡£
        """
        system_prompt = """ä½ æ˜¯é¡¹ç›®ç®¡ç†ä¸“å®¶ã€‚æ ¹æ®é€‰å®šçš„é€‰é¢˜ï¼Œåˆ›å»ºåä½œæ¸…å•ã€‚

è¾“å‡ºæ ¼å¼ï¼š
## AIè´Ÿè´£çš„ä»»åŠ¡
- [ ] ä»»åŠ¡1
- [ ] ä»»åŠ¡2

## ç”¨æˆ·éœ€è¦æä¾›çš„å†…å®¹
- [ ] çœŸå®æ¡ˆä¾‹ï¼šxxx
- [ ] ä¸ªäººè§‚ç‚¹ï¼šxxx
- [ ] æ•°æ®æ”¯æŒï¼šxxx

## æ³¨æ„äº‹é¡¹
- ä¸ç¼–é€ æ•°æ®
- ä¸ä½¿ç”¨å¥—è¯
"""
        
        think_aloud = "ğŸ“ æ­£åœ¨ç”Ÿæˆåä½œæ¸…å•..."
        
        result = await ai_service.generate_content(
            system_prompt=system_prompt,
            user_message=f"ä¸ºä»¥ä¸‹é€‰é¢˜åˆ›å»ºåä½œæ¸…å•ï¼š\n\n{selected_topic}",
            temperature=0.3
        )
        
        return {
            "output": result,
            "think_aloud": think_aloud
        }
    
    async def execute_step_5(
        self, 
        selected_topic: str, 
        channel_id: str,
        task_id: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Step 5: é£æ ¼ä¸ç´ ææ£€ç´¢ (RAG æ ¸å¿ƒ)
        
        æ ¸å¿ƒåŠŸèƒ½ï¼š
        1. ä»æ•°æ®åº“æ£€ç´¢ä¸é€‰é¢˜ç›¸å…³çš„çœŸå®ç´ æ
        2. ä¸¥æ ¼æŒ‰ channel_id è¿‡æ»¤ï¼Œé˜²æ­¢è·¨é¢‘é“æ±¡æŸ“
        3. å°†æ£€ç´¢åˆ°çš„ç´ æä½œä¸º context ä¼ ç»™ä¸‹ä¸€æ­¥
        """
        channel_config = self.load_channel_config(channel_id)
        
        think_aloud = "[Step 5] å¼€å§‹é£æ ¼ä¸ç´ ææ£€ç´¢...\n"
        
        # ====================================================================
        # 1. ä»æ•°æ®åº“æ£€ç´¢çœŸå®ç´ æ
        # ====================================================================
        think_aloud += "\n[RAG] æ­£åœ¨ä»ç´ æåº“æ£€ç´¢ç›¸å…³ç´ æ...\n"
        think_aloud += f"  - é¢‘é“è¿‡æ»¤: {channel_id}\n"
        
        # è·å–é¢‘é“çš„æ•°æ®åº“ ID
        channel_data = db_service.get_channel_by_slug(channel_id)
        
        retrieved_materials = []
        if channel_data:
            # ä»æ•°æ®åº“æ£€ç´¢ç´ æï¼ˆå½“å‰ä½¿ç”¨å…³é”®è¯åŒ¹é…ï¼Œåç»­å¯å‡çº§ä¸ºå‘é‡æ£€ç´¢ï¼‰
            # ä»é€‰é¢˜ä¸­æå–å…³é”®è¯
            keywords = self._extract_keywords(selected_topic)
            think_aloud += f"  - æ£€ç´¢å…³é”®è¯: {', '.join(keywords)}\n"
            
            # æ‰§è¡Œæ£€ç´¢ï¼ˆå¸¦é¢‘é“éš”ç¦»ï¼‰
            retrieved_materials = db_service.search_materials_by_keywords(
                channel_id=channel_data["id"],
                keywords=keywords,
                limit=5
            )
            
            think_aloud += f"  - æ£€ç´¢åˆ° {len(retrieved_materials)} æ¡ç›¸å…³ç´ æ\n"
        
        # å¦‚æœæ²¡æœ‰æ£€ç´¢åˆ°ï¼Œè·å–é¢‘é“çš„é€šç”¨ç´ æ
        if not retrieved_materials and channel_data:
            think_aloud += "  - æœªæ‰¾åˆ°ç²¾ç¡®åŒ¹é…ï¼Œè·å–é¢‘é“é€šç”¨ç´ æ...\n"
            retrieved_materials = db_service.get_materials_by_channel(
                channel_id=channel_data["id"],
                limit=5
            )
        
        # ====================================================================
        # 2. æ ¼å¼åŒ–æ£€ç´¢åˆ°çš„ç´ æ
        # ====================================================================
        materials_context = ""
        if retrieved_materials:
            materials_context = "\n\n## ä»ç´ æåº“æ£€ç´¢åˆ°çš„çœŸå®ç´ æ\n"
            materials_context += "ï¼ˆä»¥ä¸‹ç´ ææ¥è‡ª15å¹´ç§¯ç´¯çš„çœŸå®ç»å†ï¼Œè¯·åœ¨åˆ›ä½œä¸­è‡ªç„¶èå…¥ï¼‰\n\n"
            
            for i, mat in enumerate(retrieved_materials, 1):
                materials_context += f"### ç´ æ{i} [{mat['material_type']}]\n"
                materials_context += f"{mat['content']}\n"
                if mat.get('source'):
                    materials_context += f"*æ¥æº: {mat['source']}*\n"
                materials_context += "\n"
            
            think_aloud += f"\n[RAG] å·²æ³¨å…¥ {len(retrieved_materials)} æ¡çœŸå®ç´ æåˆ° Prompt\n"
        else:
            think_aloud += "\n[WARN] ç´ æåº“ä¸­æš‚æ— ç›¸å…³ç´ æï¼Œè¯·åœ¨åˆ›ä½œæ—¶æ³¨å…¥çœŸå®ç»å†\n"
        
        # ====================================================================
        # 3. ç”Ÿæˆé£æ ¼åˆ†æ
        # ====================================================================
        system_prompt = f"""ä½ æ˜¯ç´ æç®¡ç†ä¸“å®¶ã€‚æ ¹æ®é€‰é¢˜ï¼Œåˆ†æé£æ ¼è¦æ±‚å¹¶æ•´åˆæ£€ç´¢åˆ°çš„ç´ æã€‚

é¢‘é“ï¼š{channel_config['channel_name']}
ç´ ææ ‡ç­¾ï¼š{', '.join(channel_config['material_tags'])}

{materials_context}

è¾“å‡ºæ ¼å¼ï¼š
## é£æ ¼å‚è€ƒè¦ç‚¹
- å¼€å¤´æ–¹å¼ï¼šxxx
- è¯­è¨€ç‰¹ç‚¹ï¼šxxx
- æ®µè½èŠ‚å¥ï¼šxxx

## å·²æ£€ç´¢åˆ°çš„å¯ç”¨ç´ æ
ï¼ˆåˆ—å‡ºä¸Šé¢æ¯æ¡ç´ æçš„ä½¿ç”¨å»ºè®®ï¼‰

## ç´ æä½¿ç”¨å»ºè®®
1. åœ¨xxxä½ç½®å¯ä»¥èå…¥ç´ æ1çš„xxx
2. ...

## å“ç‰Œç‰¹è‰²å…ƒç´ 
{json.dumps(channel_config.get('brand_metaphors', {}), ensure_ascii=False, indent=2) if channel_config.get('brand_metaphors') else 'æ— '}
"""
        
        result = await ai_service.generate_content(
            system_prompt=system_prompt,
            user_message=f"ä¸ºä»¥ä¸‹é€‰é¢˜åˆ¶å®šé£æ ¼å’Œç´ æä½¿ç”¨æ–¹æ¡ˆï¼š\n\n{selected_topic}",
            temperature=0.5
        )
        
        # å°†ç´ æ context é™„åŠ åˆ°è¾“å‡ºä¸­ï¼Œä¾› Step 7 ä½¿ç”¨
        final_output = result + "\n\n---\n" + materials_context
        
        # æŒä¹…åŒ– Think Aloud
        if task_id:
            db_service.add_think_aloud_log(task_id, 5, think_aloud)
        
        return {
            "output": final_output,
            "think_aloud": think_aloud,
            "retrieved_materials": retrieved_materials  # ä¾›å‰ç«¯å±•ç¤º
        }
    
    def _extract_keywords(self, text: str) -> List[str]:
        """ä»æ–‡æœ¬ä¸­æå–å…³é”®è¯ï¼ˆç®€å•å®ç°ï¼‰"""
        # ç§»é™¤å¸¸è§åœç”¨è¯ï¼Œæå–å…³é”®è¯
        stop_words = {'çš„', 'æ˜¯', 'åœ¨', 'å’Œ', 'äº†', 'ä¸', 'å¯¹', 'ä¸º', 'ä»¥', 'ç­‰', 
                      'è¿™', 'é‚£', 'å°±', 'ä¹Ÿ', 'éƒ½', 'è¦', 'èƒ½', 'ä¼š', 'å¯ä»¥', 'åº”è¯¥',
                      'ä¸€ä¸ª', 'æˆ‘ä»¬', 'ä»–ä»¬', 'ä»€ä¹ˆ', 'æ€ä¹ˆ', 'å¦‚ä½•', 'ä¸ºä»€ä¹ˆ'}
        
        # ç®€å•åˆ†è¯ï¼ˆæŒ‰æ ‡ç‚¹å’Œç©ºæ ¼ï¼‰
        import re
        words = re.split(r'[ï¼Œã€‚ã€ï¼ï¼Ÿï¼šï¼›""''ï¼ˆï¼‰\s]+', text)
        
        # è¿‡æ»¤åœç”¨è¯å’ŒçŸ­è¯
        keywords = [
            w.strip() for w in words 
            if w.strip() and len(w.strip()) >= 2 and w.strip() not in stop_words
        ]
        
        # å–å‰10ä¸ªå…³é”®è¯
        return keywords[:10]
    
    async def execute_step_6(self) -> Dict[str, Any]:
        """
        Step 6: æŒ‚èµ·ç­‰å¾…ï¼ˆæ•°æ®ç¡®è®¤å¡ç‚¹ï¼‰
        """
        think_aloud = "â¸ï¸ æŒ‚èµ·ç­‰å¾…ç”¨æˆ·ç¡®è®¤æ‰€æœ‰å¿…éœ€ç´ æå·²å°±ç»ª..."
        
        result = """## æ•°æ®ç¡®è®¤æ¸…å•

è¯·ç¡®è®¤ä»¥ä¸‹å†…å®¹å·²å‡†å¤‡å¥½ï¼š
- [ ] çœŸå®æ¡ˆä¾‹å’Œç»å†
- [ ] ä¸ªäººè§‚ç‚¹å’Œæ€åº¦
- [ ] å¿…è¦çš„æ•°æ®æ”¯æŒ
- [ ] å…¶ä»–å…³é”®ä¿¡æ¯

âš ï¸ é‡è¦æé†’ï¼š
- ç»ä¸ç¼–é€ è™šå‡ä¿¡æ¯
- å®å¯ç­‰å¾…ä¹Ÿä¸çå†™
- æ‰€æœ‰æ•°æ®å¿…é¡»æœ‰æ¥æº

ç¡®è®¤æ— è¯¯åï¼Œç‚¹å‡»"ç»§ç»­"è¿›å…¥åˆ›ä½œé˜¶æ®µã€‚
"""
        
        return {
            "output": result,
            "think_aloud": think_aloud,
            "is_checkpoint": True  # å¡ç‚¹ï¼Œéœ€è¦ç”¨æˆ·ç¡®è®¤
        }
    
    async def execute_step_7(
        self,
        selected_topic: str,
        style_guide: str,
        materials: str,
        channel_id: str,
        word_count: int = 1500  # é»˜è®¤å­—æ•°é™åˆ¶
    ) -> Dict[str, Any]:
        """
        Step 7: åˆç¨¿åˆ›ä½œ
        """
        channel_config = self.load_channel_config(channel_id)
        
        # æ„å»ºSystem Prompt - å¢å¼ºå­—æ•°æ§åˆ¶
        system_prompt = f"""{channel_config['system_prompt']['role']}

## âš ï¸ é‡è¦ï¼šå­—æ•°è¦æ±‚ï¼ˆå¿…é¡»ä¸¥æ ¼éµå®ˆï¼‰
- ç›®æ ‡å­—æ•°ï¼š{word_count}å­—
- å­—æ•°èŒƒå›´ï¼š{int(word_count * 0.9)}å­— ~ {word_count}å­—
- ä¸¥ç¦è¶…è¿‡ç›®æ ‡å­—æ•°ï¼å®å¯å°‘å†™ä¹Ÿä¸è¦è¶…å­—æ•°
- å†™ä½œå‰å…ˆè§„åˆ’å¥½å„éƒ¨åˆ†ç¯‡å¹…ï¼Œç¡®ä¿æ€»å­—æ•°åœ¨èŒƒå›´å†…

## å†™ä½œé£æ ¼è¦æ±‚
{chr(10).join(['- ' + style for style in channel_config['system_prompt']['writing_style']])}

## è¯­è°ƒè§„èŒƒ
ç¦æ­¢ä½¿ç”¨ï¼š{', '.join(channel_config['system_prompt']['tone_guidelines']['ç¦æ­¢ä½¿ç”¨'])}
æ¨èä½¿ç”¨ï¼š{', '.join(channel_config['system_prompt']['tone_guidelines']['æ¨èä½¿ç”¨'])}

## é¢‘é“è§„åˆ™
å¿…é¡»éµå®ˆï¼š
{chr(10).join(['- ' + rule for rule in channel_config['channel_specific_rules']['must_do']])}

ä¸¥æ ¼ç¦æ­¢ï¼š
{chr(10).join(['- ' + rule for rule in channel_config['channel_specific_rules']['must_not_do']])}

## å±è”½è¯
ä»¥ä¸‹è¡¨è¾¾ç»å¯¹ç¦æ­¢ä½¿ç”¨ï¼š
{', '.join(channel_config['blocked_phrases'])}

## åˆ›ä½œè¦æ±‚
1. èå…¥çœŸå®è§‚å¯Ÿå’Œæ¡ˆä¾‹
2. æœ‰ä¸ªäººæ€åº¦å’Œæ¸©åº¦
3. é¿å…ç©ºæ´å¥—è¯
4. æ®µè½èŠ‚å¥é€‚ä¸­ï¼ˆæ¯æ®µ150-200å­—ï¼‰
5. å¥å­é•¿åº¦æ§åˆ¶ï¼ˆé¿å…è¶…è¿‡40å­—çš„é•¿å¥ï¼‰
6. ã€é‡è¦ã€‘ä¸¥æ ¼æ§åˆ¶å­—æ•°ï¼Œä¸å¾—è¶…è¿‡{word_count}å­—
"""
        
        think_aloud = f"âœï¸ å¼€å§‹åˆ›ä½œåˆç¨¿...\n\né¢‘é“ï¼š{channel_config['channel_name']}\nè°ƒæ€§ï¼š{channel_config['brand_personality']}\nå­—æ•°è¦æ±‚ï¼š{word_count}å­—\n\næ­£åœ¨èå…¥å“ç‰Œé£æ ¼å’ŒçœŸå®ç´ æ..."
        
        user_message = f"""è¯·åˆ›ä½œæ–‡ç« åˆç¨¿ã€‚

## é€‰é¢˜
{selected_topic}

## é£æ ¼æŒ‡å—
{style_guide}

## å¯ç”¨ç´ æ
{materials}

## âš ï¸ å­—æ•°è¦æ±‚
- æ–‡ç« æ€»å­—æ•°å¿…é¡»æ§åˆ¶åœ¨ {int(word_count * 0.9)} ~ {word_count} å­—ä¹‹é—´
- åˆ›ä½œå®Œæˆåè¯·æ£€æŸ¥å­—æ•°ï¼Œå¦‚è¶…è¿‡å­—æ•°é™åˆ¶è¯·è‡ªè¡Œç²¾ç®€

è¯·å¼€å§‹åˆ›ä½œï¼Œç›´æ¥è¾“å‡ºæ–‡ç« å†…å®¹ï¼ˆä¸è¦è¶…è¿‡{word_count}å­—ï¼‰ã€‚
"""
        
        # æ ¹æ®å­—æ•°åŠ¨æ€è°ƒæ•´ max_tokensï¼ˆä¸­æ–‡çº¦ 1.5 å­—ç¬¦/tokenï¼‰
        estimated_tokens = min(int(word_count * 1.5), 4000)
        
        result = await ai_service.generate_content(
            system_prompt=system_prompt,
            user_message=user_message,
            temperature=0.7,
            max_tokens=estimated_tokens
        )
        
        return {
            "output": result,
            "think_aloud": think_aloud
        }
    
    async def execute_step_8(self, draft: str, channel_id: str, word_count: int = 1500) -> Dict[str, Any]:
        """
        Step 8: ä¸‰éå®¡æ ¡æœºåˆ¶
        """
        channel_config = self.load_channel_config(channel_id)
        blocked_words_config = self.load_blocked_words()
        
        # è®¡ç®—å½“å‰è‰ç¨¿å­—æ•°
        current_word_count = len(draft)
        is_over_limit = current_word_count > word_count
        
        # æ„å»ºå±è”½è¯åˆ—è¡¨
        blocked_phrases = []
        for category in blocked_words_config['categories'].values():
            for pattern in category['patterns']:
                blocked_phrases.append(f"- {pattern['phrase']} â†’ {pattern['replacement']} ï¼ˆåŸå› ï¼š{pattern['reason']}ï¼‰")
        
        # æ ¹æ®æ˜¯å¦è¶…å­—æ•°è°ƒæ•´å®¡æ ¡è¦æ±‚
        word_count_instruction = ""
        if is_over_limit:
            word_count_instruction = f"""
## âš ï¸ å­—æ•°è¶…é™è­¦å‘Š
- å½“å‰å­—æ•°ï¼š{current_word_count}å­—
- ç›®æ ‡å­—æ•°ï¼š{word_count}å­—
- è¶…å‡ºå­—æ•°ï¼š{current_word_count - word_count}å­—
- ã€å¿…é¡»æ‰§è¡Œã€‘åœ¨å®¡æ ¡è¿‡ç¨‹ä¸­ç²¾ç®€å†…å®¹ï¼Œåˆ é™¤å†—ä½™è¡¨è¾¾ï¼Œç¡®ä¿æœ€ç»ˆç‰ˆæœ¬ä¸è¶…è¿‡{word_count}å­—
"""
        else:
            word_count_instruction = f"""
## å­—æ•°æ£€æŸ¥
- å½“å‰å­—æ•°ï¼š{current_word_count}å­—
- ç›®æ ‡å­—æ•°ï¼š{word_count}å­—
- å­—æ•°ç¬¦åˆè¦æ±‚ï¼Œè¯·ä¿æŒåœ¨{word_count}å­—ä»¥å†…
"""
        
        system_prompt = f"""ä½ æ˜¯ä¸“ä¸šçš„å†…å®¹å®¡æ ¡ä¸“å®¶ã€‚è¯·å¯¹æ–‡ç« è¿›è¡Œä¸‰éå®¡æ ¡ã€‚
{word_count_instruction}

## ä¸€å®¡ï¼šå†…å®¹å®¡æ ¡
- äº‹å®å‡†ç¡®æ€§
- é€»è¾‘æ¸…æ™°åº¦
- è®ºè¯å……åˆ†æ€§
- æ˜¯å¦æœ‰ç¼–é€ å†…å®¹

## äºŒå®¡ï¼šé£æ ¼å®¡æ ¡ï¼ˆå»AIå‘³ï¼‰
é¢‘é“è¦æ±‚ï¼š{channel_config['brand_personality']}

å…¨å±€å±è”½è¯ï¼ˆå¿…é¡»æ£€æŸ¥ï¼‰ï¼š
{chr(10).join(blocked_phrases[:20])}  

é¢‘é“å±è”½è¯ï¼š
{', '.join(channel_config['blocked_phrases'])}

## ä¸‰å®¡ï¼šç»†èŠ‚æ‰“ç£¨ + å­—æ•°æ§åˆ¶
- å¥å­é•¿åº¦ï¼ˆæ‹†åˆ†è¶…è¿‡40å­—çš„é•¿å¥ï¼‰
- æ®µè½é•¿åº¦ï¼ˆæ¯æ®µä¸è¶…è¿‡200å­—ï¼‰
- æ ‡ç‚¹ç¬¦å·
- è‡ªç„¶è¯­è°ƒ
- æƒ…æ„Ÿå…±é¸£
- ã€é‡è¦ã€‘ç¡®ä¿æ€»å­—æ•°ä¸è¶…è¿‡{word_count}å­—

è¾“å‡ºæ ¼å¼ï¼š
## å®¡æ ¡æŠ¥å‘Š

### å‘ç°çš„é—®é¢˜
1. [å†…å®¹] xxx
2. [é£æ ¼] xxx
3. [ç»†èŠ‚] xxx
4. [å­—æ•°] å½“å‰xxxå­—ï¼Œ{"éœ€è¦ç²¾ç®€" if is_over_limit else "ç¬¦åˆè¦æ±‚"}

### ä¿®æ”¹å»ºè®®
...

### ä¿®æ”¹åç‰ˆæœ¬
ï¼ˆè¾“å‡ºå®Œæ•´çš„ä¿®æ”¹åæ–‡ç« ï¼Œç¡®ä¿ä¸è¶…è¿‡{word_count}å­—ï¼‰
"""
        
        think_aloud = f"ğŸ” å¼€å§‹ä¸‰éå®¡æ ¡...\n\nå½“å‰å­—æ•°ï¼š{current_word_count}å­—ï¼ˆç›®æ ‡ï¼š{word_count}å­—ï¼‰\n\nç¬¬ä¸€éï¼šå†…å®¹å®¡æ ¡\nç¬¬äºŒéï¼šé£æ ¼å®¡æ ¡ï¼ˆå»AIå‘³ï¼‰\nç¬¬ä¸‰éï¼šç»†èŠ‚æ‰“ç£¨ + å­—æ•°æ§åˆ¶"
        
        # åŠ¨æ€è°ƒæ•´ max_tokens
        estimated_tokens = min(int(word_count * 2), 6000)  # é¢„ç•™å®¡æ ¡æŠ¥å‘Šç©ºé—´
        
        result = await ai_service.generate_content(
            system_prompt=system_prompt,
            user_message=f"è¯·å¯¹ä»¥ä¸‹æ–‡ç« è¿›è¡Œä¸‰éå®¡æ ¡ï¼ˆæ³¨æ„å­—æ•°é™åˆ¶{word_count}å­—ï¼‰ï¼š\n\n{draft}",
            temperature=0.3,
            max_tokens=estimated_tokens
        )
        
        return {
            "output": result,
            "think_aloud": think_aloud
        }
    
    async def execute_step_9(self, final_article: str) -> Dict[str, Any]:
        """
        Step 9: æ–‡ç« é…å›¾
        """
        system_prompt = """ä½ æ˜¯é…å›¾æ–¹æ¡ˆä¸“å®¶ã€‚æ ¹æ®æ–‡ç« å†…å®¹ï¼Œæä¾›é…å›¾å»ºè®®ã€‚

è¾“å‡ºæ ¼å¼ï¼š
## é…å›¾æ–¹æ¡ˆ

### å›¾1ï¼šæ ‡é¢˜/ä½ç½®
- æè¿°ï¼šxxx
- é£æ ¼ï¼šæ’ç”»/ç…§ç‰‡/å›¾è¡¨
- AIç»˜å›¾æç¤ºè¯ï¼šxxx

### å›¾2ï¼šæ ‡é¢˜/ä½ç½®
...

## Markdownä»£ç 
```markdown
![å›¾1æè¿°](å›¾ç‰‡è·¯å¾„)

æ–‡ç« å†…å®¹...

![å›¾2æè¿°](å›¾ç‰‡è·¯å¾„)
```

æ³¨æ„ï¼š
- é…å›¾è¦ä¸å†…å®¹ç›¸å…³
- 5-8å¼ ä¸ºå®œ
- æä¾›æ¸…æ™°çš„AIç»˜å›¾æç¤ºè¯
"""
        
        think_aloud = "ğŸ–¼ï¸ æ­£åœ¨ç”Ÿæˆé…å›¾æ–¹æ¡ˆ..."
        
        result = await ai_service.generate_content(
            system_prompt=system_prompt,
            user_message=f"ä¸ºä»¥ä¸‹æ–‡ç« æä¾›é…å›¾æ–¹æ¡ˆï¼š\n\n{final_article[:2000]}...",
            temperature=0.5
        )
        
        return {
            "output": result,
            "think_aloud": think_aloud
        }

# å…¨å±€å·¥ä½œæµå¼•æ“å®ä¾‹
workflow_engine = WorkflowEngine()

